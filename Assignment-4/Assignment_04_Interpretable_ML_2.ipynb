{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akalpit23/Interpretable-ML/blob/main/Assignment-4/Assignment_04_Interpretable_ML_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVw9qCsAjDHV"
      },
      "source": [
        "# AIPI 590 - XAI | Assignment #04\n",
        "\n",
        "\n",
        "\n",
        "## Akalpit Dawkhar\n",
        "\n",
        "### **Interpretable ML-2**\n",
        "\n",
        "### Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will demonstrate and evaluate the interpretability of different rule-based models on a selected dataset. The focus of this assignment is to explore how these models generate interpretable decision rules and understand how well they perform on a classification problem.\n",
        "\n",
        "## Models Used\n",
        "We will implement three algorithms from the `imodels` library:\n",
        "1. **RuleFit**: A hybrid model that combines decision trees and linear models. It extracts interpretable if-then rules from decision trees and fits a sparse linear model, providing a balance between interpretability and predictive power.\n",
        "2. **Greedy Rule List Classifier**: A rule-based model that constructs a list of decision rules in a greedy fashion.\n",
        "3. **APLR (Automatic Piecewise Linear Regression)**: A model that learns piecewise linear functions for each feature, offering both interpretability and flexibility in modeling non-linear relationships in the data.\n"
      ],
      "metadata": {
        "id": "vo941oCW6vSo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tkdj9E304ucE"
      },
      "source": [
        "# 1. Importing neccesarry libraries, loading and preprocessing the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaJ53nMMtljd",
        "outputId": "db14b9a3-833b-450e-e8dc-eded4379c60a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning:\n",
            "\n",
            "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# !pip install skope-rules shap lime scikit-learn seaborn skope-rules matplotlib setuptools six rulefit --upgrade\n",
        "# !pip install --upgrade imodels\n",
        "# !pip install interpret\n",
        "# !pip install collections\n",
        "# !pip show imodels graphviz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBfJDCaVi1K0",
        "outputId": "99cf6388-f159-4ded-c581-4c38b88ec3b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning:\n",
            "\n",
            "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import shap\n",
        "import lime\n",
        "import sklearn\n",
        "import collections\n",
        "import demo_helper\n",
        "import six\n",
        "import os\n",
        "import graphviz\n",
        "collections.Iterable = collections.abc.Iterable\n",
        "sklearn.externals.six = six\n",
        "from scipy.io import arff\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc, accuracy_score, precision_recall_curve, classification_report\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler ,OneHotEncoder, label_binarize, KBinsDiscretizer\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, precision_recall_curve, roc_auc_score\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.ensemble import BaggingClassifier, BaggingRegressor\n",
        "from sklearn import tree\n",
        "from itertools import cycle\n",
        "import skrules.skope_rules\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "import six\n",
        "from imodels import  RuleFitRegressor, BoostedRulesClassifier, GreedyRuleListClassifier, GreedyTreeClassifier, GreedyTreeRegressor, OneRClassifier , HSTreeClassifierCV\n",
        "from rulefit import RuleFit\n",
        "from skrules import SkopeRules\n",
        "from skrules import SkopeRules as SkopeRulesClassifier\n",
        "from interpret.glassbox import ExplainableBoostingClassifier\n",
        "from interpret import set_visualize_provider\n",
        "from interpret.provider import InlineProvider\n",
        "set_visualize_provider(InlineProvider())\n",
        "from interpret.glassbox import APLRClassifier\n",
        "from interpret import show\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Monkey Patches"
      ],
      "metadata": {
        "id": "sqvkzpLe77AC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "CPZSNS9E4ucG",
        "outputId": "550270a8-b9e9-4e4a-e11c-8ff422e1b25f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning:\n",
            "\n",
            "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'kwargs' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-766c7f0ea694>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mruntime\u001b[0m \u001b[0mwithout\u001b[0m \u001b[0mdirectly\u001b[0m \u001b[0maltering\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msource\u001b[0m \u001b[0mcode\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mimodels\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mskrules\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \"\"\"\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;34m'base_estimator'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'estimator'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'base_estimator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0moriginal_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'kwargs' is not defined"
          ]
        }
      ],
      "source": [
        "def patched_init(*args, **kwargs):\n",
        "     \"\"\"\n",
        "    Patched __init__ method for BaggingClassifier in the skrules.skope_rules module.\n",
        "\n",
        "    This patch modifies the constructor (__init__) of the BaggingClassifier class to ensure\n",
        "    compatibility with updated scikit-learn or model APIs. Specifically, it renames the\n",
        "    'base_estimator' argument to 'estimator', as some versions of libraries may expect\n",
        "    'estimator' instead of 'base_estimator'.\n",
        "\n",
        "    Parameters:\n",
        "    *args: tuple\n",
        "        Positional arguments that are passed to the original __init__ method of\n",
        "        BaggingClassifier.\n",
        "\n",
        "    **kwargs: dict\n",
        "        Keyword arguments that are passed to the original __init__ method of\n",
        "        BaggingClassifier. If 'base_estimator' is provided, it is renamed to 'estimator'\n",
        "        before passing to the original __init__ method.\n",
        "\n",
        "    Returns:\n",
        "    object\n",
        "        The initialized BaggingClassifier object after calling the original __init__\n",
        "        with modified arguments, if applicable.\n",
        "\n",
        "    Notes:\n",
        "    ------\n",
        "    This patch is useful for maintaining backward compatibility with older versions of\n",
        "    code or when there is a naming conflict in the API. It modifies the constructor at\n",
        "    runtime without directly altering the source code of the `imodels` or `skrules` library.\n",
        "    \"\"\"\n",
        "if 'base_estimator' in kwargs:\n",
        "    kwargs['estimator'] = kwargs.pop('base_estimator')\n",
        "return original_init(*args, **kwargs)\n",
        "\n",
        "original_init = skrules.skope_rules.BaggingClassifier.__init__\n",
        "skrules.skope_rules.BaggingClassifier.__init__ = patched_init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9arjG8z4ucG"
      },
      "outputs": [],
      "source": [
        "def patch_estimator(cls):\n",
        "    \"\"\"\n",
        "    Patched initialization method for BaggingClassifier in the skrules.skope_rules module.\n",
        "\n",
        "    This function modifies the '__init__' method of the BaggingClassifier class to replace\n",
        "    the 'base_estimator' keyword argument with 'estimator' to maintain compatibility\n",
        "    with updated API changes or requirements in the 'skrules.skope_rules' package.\n",
        "\n",
        "    Parameters:\n",
        "    *args: tuple\n",
        "        Positional arguments passed to the original __init__ method of BaggingClassifier.\n",
        "\n",
        "    **kwargs: dict\n",
        "        Keyword arguments passed to the original __init__ method of BaggingClassifier.\n",
        "        If 'base_estimator' is present in the kwargs, it is replaced with 'estimator'.\n",
        "\n",
        "    Returns:\n",
        "    The result of calling the original __init__ method of BaggingClassifier with modified\n",
        "    arguments and keyword arguments.\n",
        "\n",
        "    Notes:\n",
        "    This patch is necessary because some versions of scikit-learn and other model\n",
        "    implementations may use 'estimator' instead of 'base_estimator'. This ensures\n",
        "    compatibility without modifying the underlying library directly.\n",
        "    \"\"\"\n",
        "    original_init = cls.__init__\n",
        "    def patched_init(*args, **kwargs):\n",
        "        if 'base_estimator' in kwargs:\n",
        "            kwargs['estimator'] = kwargs.pop('base_estimator')\n",
        "        return original_init(*args, **kwargs)\n",
        "    cls.__init__ = patched_init\n",
        "\n",
        "patch_estimator(skrules.skope_rules.BaggingClassifier)\n",
        "patch_estimator(skrules.skope_rules.BaggingRegressor)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We load the Diabetes dataset from `sklearn.datasets` and prepare it for model training. The dataset contains medical data such as age, BMI, and blood serum measurements used to predict disease progression.\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "brBLMytI7mzM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBPtYzPl4ucH"
      },
      "outputs": [],
      "source": [
        "# Load the diabetes dataset\n",
        "diabetes = load_diabetes()\n",
        "\n",
        "# Convert the continuous target to binary\n",
        "y_median = np.median(diabetes.target)\n",
        "y = (diabetes.target > y_median).astype(int)  # labels 0-1\n",
        "\n",
        "# Prepare the feature data\n",
        "X = diabetes.data.astype('float32')\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.75)  # split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avNejlcltlje"
      },
      "outputs": [],
      "source": [
        "# Convert to DataFrame\n",
        "diabetes_df = pd.DataFrame(data=diabetes.data, columns=diabetes.feature_names)\n",
        "\n",
        "# Print the first 5 rows\n",
        "print(diabetes_df.head())\n",
        "\n",
        "# Get the feature names\n",
        "f_names = diabetes.feature_names\n",
        "\n",
        "# Define the original feature names\n",
        "o_names = [\"age\", \"sex\", \"bmi\", \"bp\", \"tc\", \"ldl\", \"hdl\", \"tch\", \"ltg\", \"glu\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ml6vbMk64ucH"
      },
      "source": [
        "# 2. RuleFit rule sit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yi9_bea9iw5s"
      },
      "outputs": [],
      "source": [
        "# Initialize the RuleFitRegressor\n",
        "rf = RuleFitRegressor(max_rules=10, memory_par=0.01, tree_size=4, lin_standardise=True)\n",
        "\n",
        "# Fit the model to your data\n",
        "rf.fit(X_train, y_train, feature_names=o_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVzrCuBPtlje"
      },
      "outputs": [],
      "source": [
        "# Use the model to make predictions\n",
        "predictions = rf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9zHITjgtlje"
      },
      "outputs": [],
      "source": [
        "rule_df = rf.visualize()\n",
        "rule_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHMfCXnl4ucH"
      },
      "outputs": [],
      "source": [
        "# Inspect and print the rules\n",
        "print('Rulefit visualization:')\n",
        "rules = rf._get_rules()\n",
        "rules = rules[rules.coef != 0].sort_values(\"support\", ascending=False)\n",
        "display(rules[['rule', 'coef', 'support']].style.background_gradient(cmap='Blues'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GHUJZ9_tlje"
      },
      "outputs": [],
      "source": [
        "# Calculate the mean absolute error\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "\n",
        "# Calculate the mean squared error\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "\n",
        "# Calculate the R-squared score\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "# Print the metrics\n",
        "print(f'MAE: {mae}')\n",
        "print(f'MSE: {mse}')\n",
        "print(f'R2 Score: {r2}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmYaRaKp4ucI"
      },
      "source": [
        "# 3. Greedy Rule List Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEBJMuSM4ucI"
      },
      "outputs": [],
      "source": [
        "# fit a greedy rule list\n",
        "greedy_model = GreedyRuleListClassifier()\n",
        "greedy_model.fit(X_train, y_train, feature_names=o_names)  # stores into m.rules_\n",
        "probability_grlc = greedy_model.predict_proba(X_test)\n",
        "\n",
        "# look at prediction breakdown\n",
        "demo_helper.viz_classification_preds(probability_grlc, y_test)\n",
        "\n",
        "m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRq7ATp-4ucI"
      },
      "source": [
        "# 4. Automatic Piecewise Linear Regression (APLR) (Sub-section of Tree GAM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agq02dy24ucI"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=seed\n",
        ")\n",
        "\n",
        "aplr = APLRClassifier(random_state=seed)\n",
        "aplr.fit(X_train, y_train, X_names=o_names)\n",
        "\n",
        "auc = roc_auc_score(y_test, aplr.predict_class_probabilities(X_test)[:, 1])\n",
        "print(\"AUC: {:.3f}\".format(auc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-veNC4_4ucI"
      },
      "outputs": [],
      "source": [
        "show(aplr.explain_local(X_test[:5], y_test[:5]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWex5Y3K4ucI"
      },
      "source": [
        "# 5. Greedy Tree Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vds6-ei14ucI"
      },
      "outputs": [],
      "source": [
        "# Fit the model to the training data\n",
        "gtr_model = GreedyTreeRegressor()\n",
        "gtr_model.fit(X_train, y_train)\n",
        "\n",
        "# Get the predictions\n",
        "y_pred_gtr = gtr_model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy_greedytree = accuracy_score(y_test, y_pred_gtr)\n",
        "print(f\"GreedyTreeRegressor: {accuracy_greedytree}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qimHJTua4ucJ"
      },
      "outputs": [],
      "source": [
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_gtr)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(cm, annot=True, fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "# Plot a histogram of the predicted values\n",
        "plt.hist(y_pred_gtr, bins=30, alpha=0.5, label='Predicted')\n",
        "\n",
        "# Plot a histogram of the true values\n",
        "plt.hist(y_test, bins=30, alpha=0.5, label='True')\n",
        "\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Histogram of Predicted vs True Values')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Conclusion:\n"
      ],
      "metadata": {
        "id": "caOgo7Cq9cvu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlfaYWJ0tlje"
      },
      "source": [
        "# 6. Refrences:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   https://github.com/csinva/imodels/tree/master?tab=readme-ov-file\n",
        "*   https://github.com/interpretml/interpret?tab=readme-ov-file\n",
        "*   https://github.com/christophM/rulefit\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "O_IO_r1G6D92"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}